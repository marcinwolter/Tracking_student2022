{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "GNN_MuonE_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/Tracking_student2022/blob/main/GNN_MuonE_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_vum9p0R7yZ"
      },
      "source": [
        "# Tutorial: GNNs for Particle Tracking\n",
        "\n",
        "HEP.TrkX group\n",
        "\n",
        "Steve Farrell, Daniel Murname\n",
        "\n",
        "*Feb 2020*\n",
        "\n",
        "Adapted for MuonE tracking by Marcin Wolter\n",
        "\n",
        "*July 2020*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchvision torchtext torchaudio \n",
        "!pip install torch==1.11.0+cu113  -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "NO8Pb7UPCg5f",
        "outputId": "6c0294b8-01e3-42b3-ad9d-af5235e83cfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Found existing installation: torchvision 0.11.0+cu113\n",
            "Uninstalling torchvision-0.11.0+cu113:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision-0.11.0+cu113.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.11.0+cu113\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Found existing installation: torchtext 0.11.0\n",
            "Uninstalling torchtext-0.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext-0.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchtext-0.11.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Found existing installation: torchaudio 0.10.0+cu113\n",
            "Uninstalling torchaudio-0.10.0+cu113:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchaudio-0.10.0+cu113.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchaudio/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchaudio-0.10.0+cu113\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.11.0+cu113 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.1.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZh8UpRMR7yp"
      },
      "source": [
        "# System imports\n",
        "import os\n",
        "import sys\n",
        "from pprint import pprint as pp\n",
        "from time import time as tt\n",
        "\n",
        "# External imports\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCH4u73YSkuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3db367-0c1b-4fb4-8aba-b3b87fa1cd98"
      },
      "source": [
        "print(\"PyTorch version:\",print(torch.__version__),\", CUDA version:\", torch.version.cuda)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "PyTorch version: None , CUDA version: 11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yAAs3ZiTNGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0362f13-18b1-47c8-e707-ed537c564565"
      },
      "source": [
        "#!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "#!pip install torch-geometric\n",
        "\n",
        "# MW corrected\n",
        "!pip install torch-geometric \\\n",
        "  torch-sparse \\\n",
        "  torch-scatter \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.5.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YLfHA3uSjL_"
      },
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch_scatter import scatter_add\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Get rid of RuntimeWarnings, gross\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYwHU7mHR7zR"
      },
      "source": [
        "## The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkwvGOWWR7zY"
      },
      "source": [
        "### Toy Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf6W5iVoR7zc"
      },
      "source": [
        "# Circle parameters\n",
        "num_layers = 4 #10\n",
        "height, width = 4, 4 #10, 10\n",
        "min_curve, max_curve =  15, 50\n",
        "noise = False\n",
        "event_size_min, event_size_max = 2, 3 #4, 12 #I.E. The number of true particle tracks\n",
        "max_angle= (5/6)*np.pi  # (4/6)*np.pi\n",
        "feature_scale = np.array([10,10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c-vZg1kTk-b"
      },
      "source": [
        "# Some dumb circle calculations\n",
        "def y1(x, r, a, sign):\n",
        "    return sign*np.sqrt(r**2 - a**2) + np.sqrt(r**2 - (x-a)**2)\n",
        "def y2(x, r, a, sign):\n",
        "    return sign*np.sqrt(r**2 - a**2) - np.sqrt(r**2 - (x-a)**2)\n",
        "\n",
        "# Generate random circle / helix parameters\n",
        "def rand_pars(event_size_min, event_size_max, max_curve, min_curve):\n",
        "    event_size = int(np.floor(np.random.random(1)*(event_size_max - event_size_min) + event_size_min))\n",
        "    radii = np.random.random(event_size)*(max_curve - min_curve) + min_curve\n",
        "    dirs = np.random.random(event_size)*(radii)*2 -radii\n",
        "    sign_options = np.array([-1,1])\n",
        "    signs = sign_options[np.rint(np.random.random(event_size)).astype(int)]\n",
        "    return radii, dirs, signs, event_size\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "# Generate event data from random parameters\n",
        "def gen_edge_class(event_size_min, event_size_max, curve_min, curve_max, height, num_layers, max_angle, feature_scale, iter, num_samples):\n",
        "    \n",
        "    \"\"\" Feed params into randomiser \"\"\"\n",
        "    while True:\n",
        "        radii, dirs, signs, event_size = rand_pars(event_size_min, event_size_max, curve_max, curve_min)\n",
        "        xys = []\n",
        "        X = np.empty([3,1])\n",
        "        x = np.arange(0 + height/num_layers,height + height/num_layers, height/num_layers)\n",
        "        i = 0\n",
        "        for r, d, s in zip(radii, dirs, signs):\n",
        "            y1test = y1(x, r, d, s)\n",
        "            y2test = y2(x, r, d, s)\n",
        "            #print(y1test,y2test, x)\n",
        "            if -2.5 < y1test[0] < 2.5 and not any(np.isnan(y1test)):\n",
        "                X = np.append(X, np.vstack((y1test, np.array([i]*len(y1test)), x )), axis=1)\n",
        "                i += 1\n",
        "            if -2.5 < y2test[0] < 2.5 and not any(np.isnan(y2test)):\n",
        "                X = np.append(X, np.vstack((y2test, np.array([i]*len(y2test)), x )), axis=1)\n",
        "                i += 1\n",
        "        #print(\" X \",X)       \n",
        "        X = X[:,1:].T\n",
        "        #print(\"X.T \",X)\n",
        "        np.random.shuffle(X)\n",
        "\n",
        "        e = np.array([[i,j] for layer in np.arange(num_layers-1) for i in np.argwhere(X[:,2] == layer+1) for j in np.argwhere(X[:,2] == (layer+2)) if (X[i, 0] - np.tan(max_angle/2) < X[j, 0] < X[i, 0] + np.tan(max_angle/2))]).T.squeeze()\n",
        "        #print(\"X = \",X)\n",
        "        #print(\"e = \",e)\n",
        "\n",
        "        # This handles when no edges were constructed. In that case, the randomisation is a do-over\n",
        "        try:\n",
        "            y = np.array([int(i[1] == j[1]) for i,j in zip(X[e[0]], X[e[1]])])    \n",
        "            break\n",
        "        except:\n",
        "            pass\n",
        "    if iter is not None and num_samples is not None:\n",
        "        out.update(progress(iter, num_samples))    \n",
        "    \n",
        "    X = np.array([X[:,2], X[:,0]]).T / feature_scale\n",
        "\n",
        "    data = Data(x = torch.from_numpy(X).float(), edge_index = torch.from_numpy(e), y = torch.from_numpy(y), pid = torch.from_numpy(X[:,1]))\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35sTNGChGhQn"
      },
      "source": [
        "def plot_toy_graph(event, ylim=1.):\n",
        "  \n",
        "    #print(event)\n",
        "    #print(event.x)\n",
        "    #print(event.pid)\n",
        "    #print(event.y)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    x, y = event.x[:,0].numpy(), event.x[:,1].numpy()\n",
        "    e = event.edge_index.numpy()\n",
        "#     for i, j in zip(X[e[0]], X[e[1]]):\n",
        "#         plt.plot([i[0], j[0]], [i[1], j[1]], c='b')\n",
        "    #     print(i[0], i[2], j[0], j[2])\n",
        "    plt.plot([x[e[0,:]], x[e[1,:]]], [y[e[0,:]], y[e[1,:]]], c='b')\n",
        "    plt.scatter(x, y, c='k')\n",
        "    plt.ylim(-ylim,ylim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94DIt4J6R70i"
      },
      "source": [
        "train_size, test_size = 1000, 1000\n",
        "out = display(progress(0, train_size), display_id=True)\n",
        "train_dataset = [gen_edge_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle, feature_scale, i, train_size) for i in range(train_size)]\n",
        "out = display(progress(0, test_size), display_id=True)\n",
        "test_dataset = [gen_edge_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle, feature_scale, i, test_size) for i in range(test_size)]\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsH8JVJZR71N"
      },
      "source": [
        "for k in range(10):\n",
        "   plot_toy_graph(test_dataset[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB6mrc_KR71-"
      },
      "source": [
        "The complexity of the graph depends on the angle cut we put on it. Try increasing max_angle to, say, `(5/6)*np.pi` and the graph should be more busy. The limit is of course `(6/6)*np.pi = pi` where each node will look at the full angle of available possible nodes to form an edge with. While playing with this number, run the next cell to see the proportion of fake edges to true edges (fake/true) on the above graph. This value will be extremely useful later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WXQu9GXR72B"
      },
      "source": [
        "print(\"Fake / True = \", (len(train_dataset[0].y) - train_dataset[0].y.sum().item()) / train_dataset[0].y.sum().item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eusssWsdR73x"
      },
      "source": [
        "## A Simple GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1FRm4nsR730"
      },
      "source": [
        "### Message Passing GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx0VuKz1R732"
      },
      "source": [
        "We can write out the full GNN as a class `MPNN_Network`. One can see its behaviour as:\n",
        "1. Encode (x,y) features as hidden features with an N-layer MLP called `node_encoder`\n",
        "2. Concatenate these along each edge, and feed the concatenated features into another MLP called `edge_network`\n",
        "3. Sum the output of `edge_classifier` at each node (that is, each node receives the sum of the \"messages\" of all connecting edges). This sum is fed into `node_network`\n",
        "4. Add the hidden features to the previous iteration (this helps to preserve information between messages)\n",
        "5. Repeat (2) --> (4) n_graph_iters times\n",
        "6. After the message passing loop, pass the features of each edge through an output classifier network called `edge_classifier`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPycV6mR734"
      },
      "source": [
        "def make_mlp(input_size, sizes,\n",
        "             hidden_activation='ReLU',\n",
        "             output_activation='ReLU',\n",
        "             layer_norm=False):\n",
        "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
        "    hidden_activation = getattr(nn, hidden_activation)\n",
        "    if output_activation is not None:\n",
        "        output_activation = getattr(nn, output_activation)\n",
        "    layers = []\n",
        "    n_layers = len(sizes)\n",
        "    sizes = [input_size] + sizes\n",
        "    # Hidden layers\n",
        "    for i in range(n_layers-1):\n",
        "        layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "        if layer_norm:\n",
        "            layers.append(nn.LayerNorm(sizes[i+1]))\n",
        "        layers.append(hidden_activation())\n",
        "    # Final layer\n",
        "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "    if output_activation is not None:\n",
        "        if layer_norm:\n",
        "            layers.append(nn.LayerNorm(sizes[-1]))\n",
        "        layers.append(output_activation())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class MPNN_Network(nn.Module):\n",
        "    \"\"\"\n",
        "    A message-passing graph network which takes a graph with:\n",
        "    - bi-directional edges\n",
        "    - node features, no edge features\n",
        "\n",
        "    and applies the following modules:\n",
        "    - a graph encoder (no message passing)\n",
        "    - recurrent edge and node networks\n",
        "    - an edge classifier\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_node_dim, hidden_edge_dim, in_layers, node_layers, edge_layers,\n",
        "                 n_graph_iters=1, layer_norm=True):\n",
        "        super(MPNN_Network, self).__init__()\n",
        "        self.n_graph_iters = n_graph_iters\n",
        "\n",
        "        # The node encoder transforms input node features to the hidden space\n",
        "        self.node_encoder = make_mlp(input_dim, [hidden_node_dim]*in_layers)\n",
        "\n",
        "        # The edge network computes new edge features from connected nodes\n",
        "        self.edge_network = make_mlp(2*hidden_node_dim,\n",
        "                                     [hidden_edge_dim]*edge_layers,\n",
        "                                     layer_norm=layer_norm)\n",
        "\n",
        "        # The node network computes new node features\n",
        "        self.node_network = make_mlp(hidden_node_dim + hidden_edge_dim,\n",
        "                                     [hidden_node_dim]*node_layers,\n",
        "                                     layer_norm=layer_norm)\n",
        "\n",
        "        # The edge classifier computes final edge scores\n",
        "        self.edge_classifier = make_mlp(2*hidden_node_dim,\n",
        "                                        [hidden_edge_dim, 1],\n",
        "                                        output_activation=None)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Make every edge bi-directional\n",
        "        send_idx = torch.cat([data.edge_index[0], data.edge_index[1]], dim=0)\n",
        "        recv_idx = torch.cat([data.edge_index[1], data.edge_index[0]], dim=0)\n",
        "\n",
        "        # Encode the graph features into the hidden space\n",
        "        x = self.node_encoder(data.x)\n",
        "\n",
        "        # Loop over graph iterations\n",
        "        for i in range(self.n_graph_iters):\n",
        "\n",
        "            # Previous hidden state\n",
        "            x0 = x\n",
        "\n",
        "            # Compute new edge features\n",
        "            edge_inputs = torch.cat([x[send_idx], x[recv_idx]], dim=1)\n",
        "            e = self.edge_network(edge_inputs)\n",
        "\n",
        "            # Sum edge features coming into each node\n",
        "            aggr_messages = scatter_add(e, recv_idx, dim=0, dim_size=x.shape[0])\n",
        "\n",
        "            # Compute new node features\n",
        "            node_inputs = torch.cat([x, aggr_messages], dim=1)\n",
        "            x = self.node_network(node_inputs)\n",
        "\n",
        "            # Residual connection\n",
        "            x = x + x0\n",
        "\n",
        "        # Compute final edge scores; use original edge directions only\n",
        "        start_idx, end_idx = data.edge_index\n",
        "        clf_inputs = torch.cat([x[start_idx], x[end_idx]], dim=1)\n",
        "        return self.edge_classifier(clf_inputs).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOsNvEEpR74O"
      },
      "source": [
        "Build a version of the model and print it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPSN18uR74Q"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 64, \"hidden_edge_dim\": 64, \"in_layers\": 2, \"node_layers\": 4, \"edge_layers\": 4, \"n_graph_iters\": 1, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSM30cK2R746"
      },
      "source": [
        "### Training on Toy Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQrAmWD23j0x"
      },
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data = batch.to(device)\n",
        "        pred = model(data)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float(), pos_weight=torch.tensor(weight))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
        "        total += len(pred)\n",
        "    acc = correct/total\n",
        "    return acc, total_loss\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    for batch in test_loader:\n",
        "        data = batch.to(device)\n",
        "        pred = model(data)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float(), pos_weight=torch.tensor(weight))\n",
        "        total_loss += loss.item()\n",
        "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
        "        total += len(pred)\n",
        "    acc = correct/total\n",
        "    return acc, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzAsqpGuR75G"
      },
      "source": [
        "t_loss_v = []\n",
        "t_acc_v = []\n",
        "v_loss_v = []\n",
        "v_acc_v = []\n",
        "ep = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wbNjVo3R75N"
      },
      "source": [
        "We set a weight value that is more or less the (fake / true) ratio found above. This forces the loss function to punish incorrectly classified true edges more severely. It rebalances the distribution as if there was a 1:1 true:fake ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBHqYJPaR75P"
      },
      "source": [
        "weight = 2\n",
        "\n",
        "m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 16, \"hidden_edge_dim\": 16, \"in_layers\": 1, \"node_layers\": 2, \"edge_layers\": 2, \"n_graph_iters\": 6, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
        "\n",
        "for epoch in range(200):\n",
        "    ep += 1  \n",
        "    model.train()\n",
        "    acc, total_loss = train(model, train_loader, optimizer)\n",
        "    t_loss_v.append(total_loss)\n",
        "    t_acc_v.append(acc)\n",
        "\n",
        "    model.eval()\n",
        "    acc, total_loss = evaluate(model, test_loader)\n",
        "    v_loss_v.append(total_loss)\n",
        "    v_acc_v.append(acc)\n",
        "\n",
        "    print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEjmOmtuR75e"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 5))\n",
        "axs[0].plot(np.arange(len(t_loss_v)), t_loss_v, np.arange(len(t_acc_v)), t_acc_v)\n",
        "axs[0].set_title(\"Training loss and accuracy\")\n",
        "axs[0].set_yscale(\"linear\")\n",
        "axs[1].plot(np.arange(len(v_loss_v)), v_loss_v, np.arange(len(v_acc_v)), v_acc_v)\n",
        "axs[1].set_title(\"Validation loss and accuracy\")\n",
        "axs[1].set_yscale(\"linear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEDdFqVnR75x"
      },
      "source": [
        "### Did it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fTa4sHsR75z"
      },
      "source": [
        "Running the above with 1 graph iteration gives me about 90% accuracy in 200 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT5s0J70R751"
      },
      "source": [
        "The best performance that I can get with some simple manual tuning is around 95% accuracy. We can improve the efficiency at the cost of purity by raising the weight on true edges, but the accuracy won't significantly improve. In general, the biggest changes were from increasing the width (i.e. the number of dimensions) of the hidden layers. We can visualise the performance on a particular graph, colouring true positives black, false positives red, true negatives a transparent black, and false negatives in blue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CR0cLcR752"
      },
      "source": [
        "def plot_toy_classified(event, preds, cut=0.5):\n",
        "    \n",
        "    #print(\"New event\")\n",
        "        \n",
        "    #print(event)\n",
        "    #print(event.x)\n",
        "    #print(event.pid)\n",
        "    #print(event.y)\n",
        "    #gprint(preds)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    x, y = event.x[:,0].numpy(), event.x[:,1].numpy()\n",
        "    edges = event.edge_index.numpy()\n",
        "    labels = event.y\n",
        "    plt.scatter(x, y, c='k')\n",
        "    \n",
        "    preds = preds.detach().numpy()\n",
        "    \n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        \n",
        "        #print(str('%01.2f' % preds[j])+\" \"+str(labels[j].item())+\" \"+str(x[edges[0,j]]*feature_scale)+\",\"+str(y[edges[0,j]]*feature_scale)+\" \"+str(x[edges[1,j]]*feature_scale)+\",\"+str(y[edges[1,j]]*feature_scale))\n",
        "        s = str('%01.2f' % preds[j])+\" \"+str(labels[j].item())\n",
        "        plt.text((x[edges[0,j]]+x[edges[1,j]])/2., (y[edges[0,j]]+y[edges[1,j]])/2.+np.random.random(1)*0.00, s, fontsize=12)\n",
        "\n",
        "        # False negatives\n",
        "        if preds[j] < cut and labels[j].item() > cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '--', c='b')\n",
        "\n",
        "        # False positives\n",
        "        if preds[j] > cut and labels[j].item() < cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='r', alpha=preds[j])\n",
        "\n",
        "        # True positives\n",
        "        if preds[j] > cut and labels[j].item() > cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='k', alpha=preds[j])\n",
        "                \n",
        "        # True negatives\n",
        "        if preds[j] < cut and labels[j].item() < cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='k', alpha=preds[j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIv5Ka7RR76B"
      },
      "source": [
        "for k in range(10):\n",
        "   data = test_loader.dataset[k].to(device)\n",
        "   preds = torch.sigmoid(model(data)).to('cpu')\n",
        "   plot_toy_classified(data.to('cpu'), preds, cut = 0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIo7EeyJR76L"
      },
      "source": [
        "So we can see that it's working quite well. Few missed true edges, and few misclassified fake edges. The ratio of false positives to false negatives (which can be defined with efficiency and purity) is controlled by the cut we put on the prediction score. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CBDsYlxR76N"
      },
      "source": [
        "### The effect of Message Passing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSZzzAtDR76P"
      },
      "source": [
        "In this simple example, the message passing does not do a huge amount. Going from 1 iteration to 6 iterations improves the accuracy to around 93% (from 90%). This improvement is washed out with more hidden dimensions, as one can see from the below set of tests. Try playing with more hidden node and edge dimensions (e.g. 64) and see if the message passing iterations can improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9vg_JclR76S"
      },
      "source": [
        "t_loss_v = []\n",
        "t_acc_v = []\n",
        "v_loss_v = []\n",
        "v_acc_v = []\n",
        "ep = 0\n",
        "best_acc = np.zeros(10)\n",
        "for i in range(1,2): #for i in range(1,11): # shorten to 2 iterations to speed up\n",
        "    m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 16, \"hidden_edge_dim\": 16, \"in_layers\": 1, \"node_layers\": 2, \"edge_layers\": 2, \"n_graph_iters\": i, \"layer_norm\": True}\n",
        "    model = MPNN_Network(**m_configs).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
        "    for epoch in range(200):\n",
        "        ep += 1  \n",
        "        model.train()\n",
        "        acc, total_loss = train(model, train_loader, optimizer)\n",
        "        t_loss_v.append(total_loss)\n",
        "        t_acc_v.append(acc)\n",
        "\n",
        "        model.eval()\n",
        "        acc, total_loss = evaluate(model, test_loader)\n",
        "        if acc > best_acc[i-1]: best_acc[i-1] = acc\n",
        "        v_loss_v.append(total_loss)\n",
        "        v_acc_v.append(acc)\n",
        "\n",
        "        print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc))\n",
        "plt.plot(np.arange(len(best_acc)), best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XjlMCJ_-BxA"
      },
      "source": [
        "plt.plot(np.arange(len(best_acc)), best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7koxeu9q4Gn"
      },
      "source": [
        "\n",
        "\n",
        "# **Load MuonE data and reconstruct tracks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk18NYQOrfzB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZs_yxD3FRKf"
      },
      "source": [
        "# Circle parameters\n",
        "num_layers = 14\n",
        "height, width = 10, 10\n",
        "#min_curve, max_curve =  1000, 1001 # 15, 50\n",
        "\n",
        "max_angle = 1.*np.pi\n",
        "feature_scale = 200.\n",
        "\n",
        "# x and y multiplied by this scale (to get similar x/y and z spread)\n",
        "xy_scale=100."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgK9yW_ErILc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def readMuonE():\n",
        "\n",
        "   event_file = \"/content/drive/My Drive/MuonE_tracking/hitFile_medium.csv\"\n",
        "\n",
        "   data = pd.read_csv(event_file) \n",
        "   # Preview the first 5 lines of the loaded data \n",
        "   data.head()\n",
        "\n",
        "   # Temporary nextZ  (next layer Z)\n",
        "   layerZ0 =  [-999, -16, -21, 131, 151, 477, 497, 832, 843.7, 1146, 1141, 1252.7, 1266, 1973, 1960 ]\n",
        "\n",
        "\n",
        "\n",
        "   #X = np.array([[0,0,0]])\n",
        "   #print(X)\n",
        "   \n",
        "   \n",
        "   iEventLast=data.iat[0,0]\n",
        "   k=0\n",
        "   Xcreated=False\n",
        "   #dataOUTcreated=False\n",
        "   dataOUT = []\n",
        "\n",
        "   #iterate over input data\n",
        "   for k, row in data.iterrows():\n",
        "     ll=data.iat[k,0]\n",
        "     #print(\"counter \",k,ll,iEventLast)\n",
        "     if ll != iEventLast:\n",
        "\n",
        "       '''\n",
        "       for layer in np.arange(num_layers-1):\n",
        "          print(\"XX=\",layer,X)\n",
        "          for i in np.argwhere(X[:,2] == layerZ0[layer+1]): \n",
        "            for j in np.argwhere(X[:,2] == layerZ0[layer+3]):\n",
        "               if (X[i, 0] - 20. < X[j, 0] < X[i, 0] + 20.):\n",
        "                   print(\"layer, i, j=\",layer, i, j)\n",
        "       '''\n",
        "#       e = np.array([[i,j] for layer in np.arange(num_layers-1) for i in np.argwhere(X[:,2] == layer+1) for j in np.argwhere(X[:,2] == (layer+2))  if (X[i, 0] - np.tan(max_angle/2) < X[j, 0] < X[i, 0] + np.tan(max_angle/2))]).T.squeeze()\n",
        "\n",
        "       e = np.array([[i,j] for layer in np.arange(num_layers-1) for i in np.argwhere(X[:,2] == \n",
        "              layerZ0[layer+1]) for j in np.argwhere(X[:,2] == layerZ0[layer+3])  if (X[i, 0] - np.tan(max_angle/2)*(layerZ0[layer+3]-layerZ0[layer+1]) < X[j, 0] < X[i, 0] + np.tan(max_angle/2)*(layerZ0[layer+3]-layerZ0[layer+1]))]).T.squeeze()\n",
        "\n",
        "       #print(X)\n",
        "       #print(\"e \",e) \n",
        "        # This handles when no edges were constructed. In that case, the randomisation is a do-over\n",
        "       #try:\n",
        "       y = np.array([int(i[1] == j[1]) for i,j in zip(X[e[0]], X[e[1]])])\n",
        "       #     print(\"y = \",y)     \n",
        "       #     break\n",
        "       #except:\n",
        "       #     pass\n",
        "\n",
        "       #print(\"y = \",y) \n",
        "       #if iter is not None and num_samples is not None:\n",
        "       #     out.update(progress(iter, num_samples))    \n",
        "\n",
        "\n",
        "       X = np.array([X[:,2], X[:,0]]).T / feature_scale\n",
        "\n",
        "       dataEvent = Data(x = torch.from_numpy(X).float(), edge_index = torch.from_numpy(e), y = torch.from_numpy(y), pid = torch.from_numpy(X[:,1]))\n",
        "\n",
        "       #plot_toy_graph(dataEvent, 0.2)\n",
        "\n",
        "       dataOUT.append(dataEvent)\n",
        "#       if dataOUTcreated:\n",
        "#         dataOUT = dataOUT.append(dataEvent)\n",
        "#       else:\n",
        "#         dataOUT = dataEvent \n",
        "#         dataOUTcreated = True\n",
        "\n",
        "       Xcreated = False  \n",
        "       iEventLast = ll\n",
        "\n",
        "     #print(len(X)) \n",
        "     #print(k,ll,data.iat[k,2],Xcreated) \n",
        "     if data.iat[k,2]==0 and data.iat[k,5]<3 and data.iat[k,5]>0: # select X-hit and trackID=0,1,2\n",
        "        if Xcreated:\n",
        "          X = np.append(X,np.array([[data.iat[k,1]*xy_scale, data.iat[k,5], data.iat[k,3]  ]]),axis=0)\n",
        "        else:\n",
        "          X = np.array([[data.iat[k,1]*xy_scale, data.iat[k,5], data.iat[k,3]  ]]) \n",
        "          Xcreated=True\n",
        "          #print(\"X created \",X)\n",
        "     \n",
        "   return dataOUT       \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zhaE3IHvLwu"
      },
      "source": [
        "# Read data and prepare for training\n",
        "\n",
        "data = readMuonE()\n",
        "\n",
        "\n",
        "# split data into training and test datasets\n",
        "train_dataset = []\n",
        "test_dataset = []\n",
        "for k in range(len(data)):\n",
        "  if (k%2 == 0):\n",
        "    test_dataset.append(data[k])\n",
        "  else:\n",
        "    train_dataset.append(data[k])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)    \n",
        "\n",
        "# Display few events\n",
        "for k in range(10):\n",
        "   plot_toy_graph(train_loader.dataset[k], 20.)\n",
        "\n",
        "\n",
        "print(\"Fake / True = \", (len(train_dataset[0].y) - train_dataset[0].y.sum().item()) / train_dataset[0].y.sum().item())\n",
        "\n",
        "print(\"Training dataset (events): \",len(train_dataset))\n",
        "print(\"Test dataset (events): \",len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6jkuybVoBqw"
      },
      "source": [
        "# **Simple GNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2JpvO0pZSy"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 64, \"hidden_edge_dim\": 64, \"in_layers\": 2, \"node_layers\": 4, \"edge_layers\": 4, \"n_graph_iters\": 1, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nzg7_Yrokqa"
      },
      "source": [
        "t_loss_v = []\n",
        "t_acc_v = []\n",
        "v_loss_v = []\n",
        "v_acc_v = []\n",
        "ep = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj7GJA-_okqv"
      },
      "source": [
        "We set a weight value that is more or less the (fake / true) ratio found above. This forces the loss function to punish incorrectly classified true edges more severely. It rebalances the distribution as if there was a 1:1 true:fake ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qlRvrHbokqw"
      },
      "source": [
        "weight = 2\n",
        "\n",
        "m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 16, \"hidden_edge_dim\": 16, \"in_layers\": 1, \"node_layers\": 2, \"edge_layers\": 2, \"n_graph_iters\": 6, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
        "\n",
        "for epoch in range(50):\n",
        "    ep += 1  \n",
        "    model.train()\n",
        "    acc, total_loss = train(model, train_loader, optimizer)\n",
        "    t_loss_v.append(total_loss)\n",
        "    t_acc_v.append(acc)\n",
        "\n",
        "    model.eval()\n",
        "    acc, total_loss = evaluate(model, test_loader)\n",
        "    v_loss_v.append(total_loss)\n",
        "    v_acc_v.append(acc)\n",
        "\n",
        "    print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgTQxer7okq8"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 5))\n",
        "axs[0].plot(np.arange(len(t_loss_v)), t_loss_v, np.arange(len(t_acc_v)), t_acc_v)\n",
        "axs[0].set_title(\"Training loss and accuracy\")\n",
        "axs[0].set_yscale(\"linear\")\n",
        "axs[1].plot(np.arange(len(v_loss_v)), v_loss_v, np.arange(len(v_acc_v)), v_acc_v)\n",
        "axs[1].set_title(\"Validation loss and accuracy\")\n",
        "axs[1].set_yscale(\"linear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry91JU8tokrG"
      },
      "source": [
        "### Did it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ3tUDzookrH"
      },
      "source": [
        "![alt text](https://)Running the above with 1 graph iteration gives me about 80% accuracy in 200 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G0frGXUokrK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-OFV5cokrM"
      },
      "source": [
        "for i in range(20):\n",
        "  data = train_loader.dataset[i].to(device)\n",
        "  preds = torch.sigmoid(model(data)).to('cpu')\n",
        "  plot_toy_classified(data.to('cpu'), preds, cut = 0.6)\n",
        "  #plot_toy_graph(train_loader.dataset[2],0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}